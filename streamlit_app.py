import streamlit as st
import pandas as pd
import numpy as np
import os
import json
import fitz  # PyMuPDF
import openai
from io import BytesIO
import faiss
import time
import base64
from datetime import datetime
from langchain.text_splitter import RecursiveCharacterTextSplitter
import pickle
import csv

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="SRO - Previs√£o de Reclama√ß√µes",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilo CSS personalizado
st.markdown("""
<style>
    .main {
        padding: 1rem;
    }
    .stAlert {
        padding: 0.5rem;
        margin-bottom: 1rem;
    }
    .risk-low {
        color: green;
        font-weight: bold;
    }
    .risk-medium {
        color: orange;
        font-weight: bold;
    }
    .risk-high {
        color: red;
        font-weight: bold;
    }
    .risk-critical {
        color: darkred;
        font-weight: bold;
        animation: blinker 1s linear infinite;
    }
    @keyframes blinker {
        50% {
            opacity: 0.7;
        }
    }
    .header-container {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-bottom: 1rem;
    }
    .logo-container {
        display: flex;
        align-items: center;
    }
    .logo {
        height: 60px;
        margin-right: 1rem;
    }
    .progress-container {
        margin-top: 1rem;
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# Cabe√ßalho da aplica√ß√£o
st.markdown("""
<div class="header-container">
    <div class="logo-container">
        <h1>üìä SRO - Sistema de Previs√£o de Reclama√ß√µes</h1>
    </div>
</div>
""", unsafe_allow_html=True)

# Inicializa√ß√£o silenciosa da chave da API OpenAI diretamente dos secrets
try:
    openai.api_key = st.secrets["OPENAI_API_KEY"]
except Exception:
    # Tratamento silencioso - n√£o exibe mensagem de erro na inicializa√ß√£o
    pass

# Sidebar para configura√ß√µes
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # Configura√ß√µes do modelo
    st.subheader("Modelo de IA")
    model = st.selectbox(
        "Selecione o modelo:",
        ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"],
        index=0
    )
    
    # Configura√ß√µes RAG
    st.subheader("Configura√ß√µes RAG")
    num_exemplos = st.slider("N√∫mero de exemplos hist√≥ricos:", 3, 10, 5)
    
    # Informa√ß√µes sobre o projeto
    st.markdown("---")
    st.markdown("### Sobre o Projeto SRO")
    st.markdown("""
    Este aplicativo utiliza Intelig√™ncia Artificial com RAG (Retrieval Augmented Generation) 
    para prever a probabilidade de reclama√ß√µes com base em coment√°rios de atendimento.
    """)

# Constantes e configura√ß√µes
FAISS_INDEX_PATH = "sro_faiss_index.bin"
CHUNKS_METADATA_PATH = "sro_chunks_metadata.csv"
HISTORICAL_DATA_PATH = "Informa√ß√µesSRO.xlsx - Planila3.csv"
CHUNK_SIZE = 500
CHUNK_OVERLAP = 100

# Fun√ß√£o para extrair texto de PDF
def extract_text_from_pdf(uploaded_file):
    try:
        pdf_bytes = uploaded_file.read()
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        
        # Tenta dividir o texto em par√°grafos ou se√ß√µes
        paragraphs = text.split('\n\n')
        if len(paragraphs) > 1:
            df = pd.DataFrame({"Comentario": [p.strip() for p in paragraphs if p.strip()]})
        else:
            df = pd.DataFrame({"Comentario": [text]})
        return df
    except Exception as e:
        st.error(f"Erro ao processar o PDF: {e}")
        return pd.DataFrame({"Comentario": []})

# Fun√ß√£o para extrair texto de JSON
def extract_text_from_json(uploaded_file):
    try:
        content = uploaded_file.read()
        data = json.loads(content)
        
        # Tenta encontrar coment√°rios no JSON
        comments = []
        
        # Fun√ß√£o recursiva para extrair valores de texto de um JSON aninhado
        def extract_text_values(obj, key_pattern="coment"):
            if isinstance(obj, dict):
                for k, v in obj.items():
                    if isinstance(v, str) and key_pattern.lower() in k.lower():
                        comments.append(v)
                    elif isinstance(v, (dict, list)):
                        extract_text_values(v, key_pattern)
            elif isinstance(obj, list):
                for item in obj:
                    extract_text_values(item, key_pattern)
        
        extract_text_values(data)
        
        if not comments:
            # Se n√£o encontrou coment√°rios espec√≠ficos, pega todos os valores de string
            def extract_all_strings(obj):
                if isinstance(obj, dict):
                    for k, v in obj.items():
                        if isinstance(v, str) and len(v) > 10:  # Strings com mais de 10 caracteres
                            comments.append(v)
                        elif isinstance(v, (dict, list)):
                            extract_all_strings(v)
                elif isinstance(obj, list):
                    for item in obj:
                        extract_all_strings(item)
            
            extract_all_strings(data)
        
        return pd.DataFrame({"Comentario": comments})
    except Exception as e:
        st.error(f"Erro ao processar o JSON: {e}")
        return pd.DataFrame({"Comentario": []})

# Fun√ß√£o para gerar embeddings usando a API da OpenAI
def get_embedding(text, model="text-embedding-ada-002"):
    if not text or not isinstance(text, str):
        return np.zeros(1536)  # Retorna um vetor de zeros se o texto for inv√°lido
    
    try:
        text = text.replace("\n", " ")
        response = openai.embeddings.create(input=[text], model=model)
        return np.array(response.data[0].embedding)
    except Exception as e:
        st.error(f"Erro ao gerar embedding: {e}")
        return np.zeros(1536)  # Retorna um vetor de zeros em caso de erro

# Fun√ß√£o para dividir texto em chunks
def split_text_into_chunks(text, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP):
    if not text or not isinstance(text, str):
        return []
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len,
        separators=["\n\n", "\n", ". ", " ", ""]
    )
    
    chunks = text_splitter.split_text(text)
    return chunks

# Fun√ß√£o para salvar o √≠ndice FAISS
def save_faiss_index(index, file_path):
    try:
        faiss.write_index(index, file_path)
        return True
    except Exception as e:
        st.error(f"Erro ao salvar √≠ndice FAISS: {e}")
        return False

# Fun√ß√£o para carregar o √≠ndice FAISS
def load_faiss_index(file_path):
    try:
        if os.path.exists(file_path):
            index = faiss.read_index(file_path)
            return index
        return None
    except Exception as e:
        st.error(f"Erro ao carregar √≠ndice FAISS: {e}")
        return None

# Fun√ß√£o para salvar metadados dos chunks
def save_chunks_metadata(chunks_metadata, file_path):
    try:
        # Remover a coluna de embedding antes de salvar para economizar espa√ßo
        if 'embedding' in chunks_metadata.columns:
            chunks_metadata = chunks_metadata.drop(columns=['embedding'])
        
        chunks_metadata.to_csv(file_path, index=False)
        return True
    except Exception as e:
        st.error(f"Erro ao salvar metadados dos chunks: {e}")
        return False

# Fun√ß√£o para carregar metadados dos chunks
def load_chunks_metadata(file_path):
    try:
        if os.path.exists(file_path):
            chunks_metadata = pd.read_csv(file_path)
            return chunks_metadata
        return None
    except Exception as e:
        st.error(f"Erro ao carregar metadados dos chunks: {e}")
        return None

# Fun√ß√£o para carregar e indexar a base hist√≥rica com chunking
@st.cache_resource
def load_and_index_historical_data_with_chunking():
    # Verificar se os arquivos de √≠ndice e metadados j√° existem
    index = load_faiss_index(FAISS_INDEX_PATH)
    chunks_metadata = load_chunks_metadata(CHUNKS_METADATA_PATH)
    
    if index is not None and chunks_metadata is not None:
        st.success("‚úÖ Base hist√≥rica carregada do cache!")
        return index, chunks_metadata
    
    # Se n√£o existirem, processar a base hist√≥rica
    st.info("üîÑ Processando base hist√≥rica pela primeira vez. Isso pode levar alguns minutos...")
    
    try:
        # Carregar o arquivo CSV
        if not os.path.exists(HISTORICAL_DATA_PATH):
            st.error(f"‚ùå Arquivo {HISTORICAL_DATA_PATH} n√£o encontrado.")
            return None, None
        
        df = pd.read_csv(HISTORICAL_DATA_PATH)
        
        # Assumir que a primeira coluna (√≠ndice 0) cont√©m os coment√°rios
        comment_col = df.columns[0]
        
        # Filtrar linhas com coment√°rios v√°lidos
        df = df[[comment_col]].rename(columns={comment_col: "Comentario"})
        df = df.dropna(subset=["Comentario"]).reset_index(drop=True)
        df = df[df["Comentario"].astype(str).str.len() > 5]  # Filtra coment√°rios muito curtos
        
        # Adicionar coluna de ID para rastreabilidade
        df["ID_Original"] = [f"OS_Hist_{i+1}" for i in range(len(df))]
        
        # Dividir coment√°rios em chunks
        all_chunks = []
        all_embeddings = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        total_comments = len(df)
        
        for i, row in enumerate(df.iterrows()):
            idx, data = row
            comment = data["Comentario"]
            id_original = data["ID_Original"]
            
            status_text.text(f"Processando coment√°rio {i+1}/{total_comments}...")
            
            # Dividir o coment√°rio em chunks
            chunks = split_text_into_chunks(str(comment))
            
            # Para cada chunk, criar um registro com metadados
            for j, chunk in enumerate(chunks):
                chunk_id = f"{id_original}_chunk_{j+1}"
                all_chunks.append({
                    "chunk_id": chunk_id,
                    "chunk_text": chunk,
                    "id_original": id_original,
                    "comentario_original": comment
                })
            
            # Atualizar barra de progresso
            progress_bar.progress((i + 1) / total_comments)
        
        # Criar DataFrame de chunks
        chunks_df = pd.DataFrame(all_chunks)
        
        # Gerar embeddings para cada chunk
        status_text.text("Gerando embeddings para chunks...")
        progress_bar.progress(0)
        
        total_chunks = len(chunks_df)
        batch_size = 100  # Processar em lotes para evitar sobrecarga da API
        
        for i in range(0, total_chunks, batch_size):
            batch = chunks_df.iloc[i:min(i+batch_size, total_chunks)]
            
            batch_embeddings = []
            for _, row in batch.iterrows():
                embedding = get_embedding(row["chunk_text"])
                batch_embeddings.append(embedding)
            
            all_embeddings.extend(batch_embeddings)
            
            # Atualizar barra de progresso
            progress_bar.progress(min(1.0, (i + batch_size) / total_chunks))
        
        # Adicionar embeddings ao DataFrame
        chunks_df["embedding"] = all_embeddings
        
        # Criar √≠ndice FAISS
        status_text.text("Criando √≠ndice FAISS...")
        
        # Converter para array numpy
        embeddings_array = np.array(all_embeddings).astype('float32')
        
        # Criar √≠ndice
        dimension = embeddings_array.shape[1]  # Dimens√£o dos embeddings
        index = faiss.IndexFlatL2(dimension)
        index.add(embeddings_array)
        
        # Salvar √≠ndice e metadados
        status_text.text("Salvando √≠ndice e metadados...")
        save_faiss_index(index, FAISS_INDEX_PATH)
        save_chunks_metadata(chunks_df, CHUNKS_METADATA_PATH)
        
        progress_bar.empty()
        status_text.empty()
        
        st.success(f"‚úÖ Base hist√≥rica processada com sucesso! {len(chunks_df)} chunks gerados de {total_comments} coment√°rios.")
        
        return index, chunks_df
    
    except Exception as e:
        st.error(f"‚ùå Erro ao processar base hist√≥rica: {e}")
        return None, None

# Fun√ß√£o para buscar chunks similares
def retrieve_similar_examples(query_embedding, index, chunks_metadata, k=5):
    if index is None or chunks_metadata is None:
        return pd.DataFrame()
    
    try:
        # Buscar os k chunks mais similares
        distances, indices = index.search(np.array([query_embedding]).astype('float32'), k)
        
        # Obter os chunks correspondentes
        similar_chunks = chunks_metadata.iloc[indices[0]]
        
        # Criar um conjunto para rastrear IDs originais j√° vistos
        seen_ids = set()
        unique_examples = []
        
        # Filtrar para obter coment√°rios originais √∫nicos
        for _, row in similar_chunks.iterrows():
            id_original = row["id_original"]
            if id_original not in seen_ids:
                seen_ids.add(id_original)
                unique_examples.append({
                    "ID_Original": id_original,
                    "Comentario_Original": row["comentario_original"],
                    "Similaridade": 1 - (distances[0][len(unique_examples)] / np.max(distances[0]) if np.max(distances[0]) > 0 else distances[0][len(unique_examples)])
                })
                
                # Limitar ao n√∫mero de exemplos solicitado
                if len(unique_examples) >= min(k, len(similar_chunks)):
                    break
        
        return pd.DataFrame(unique_examples)
    
    except Exception as e:
        st.error(f"Erro na busca de exemplos similares: {e}")
        return pd.DataFrame()

# Fun√ß√£o para analisar coment√°rio com GPT-4 usando RAG
def analisar_comentario_openai_with_rag(pedido, comentario, index, chunks_metadata, num_exemplos=5, model="gpt-4"):
    try:
        # Gerar embedding para o coment√°rio
        comentario_embedding = get_embedding(str(comentario))
        
        # Buscar exemplos similares
        similar_examples = retrieve_similar_examples(
            comentario_embedding, 
            index, 
            chunks_metadata, 
            k=num_exemplos
        )
        
        # Construir o prompt com os exemplos hist√≥ricos
        exemplos_historicos = ""
        for i, (_, row) in enumerate(similar_examples.iterrows(), 1):
            exemplos_historicos += f"Exemplo {i} (OS: {row['ID_Original']}, Similaridade: {row['Similaridade']:.2f}):\n{row['Comentario_Original']}\n\n"
        
        system_message = """Voc√™ √© um especialista em an√°lise preditiva de qualidade para uma empresa de servi√ßos automotivos (troca/reparo de vidros - VFLR, e funilaria/martelinho de ouro - RRSM). Sua fun√ß√£o √© prever a probabilidade de uma Ordem de Servi√ßo (OS) gerar uma reclama√ß√£o formal, com base em anota√ß√µes de atendimento e exemplos hist√≥ricos.

**Objetivo:** Classificar o risco de reclama√ß√£o e fornecer uma an√°lise detalhada.

**Fatores Preditivos Fundamentais (Peso de Influ√™ncia na Probabilidade):**
1.  **Frequ√™ncia de Contatos (Peso 4):** Indique no coment√°rio se o cliente j√° realizou m√∫ltiplos contatos sobre a mesma OS.
    * 1 contato: baixo risco
    * 2 contatos: m√©dio risco
    * 3+ contatos: risco elevado
2.  **Tempo de Espera (Peso 3):** Identifique atrasos ou esperas prolongadas.
    * Negocia√ß√£o Carglass: > 1 dia √∫til
    * Acompanhamento de pe√ßas (VFLR): > 5 dias √∫teis
    * Agendamento: > 1 dia √∫til
    * Confirma√ß√£o de execu√ß√£o: qualquer atraso
3.  **Falhas Processuais (Peso 2):** Detecte erros que causem retrabalho ou frustra√ß√£o.
    * Cadastro incorreto (endere√ßo/placa/modelo)
    * Solicita√ß√µes espec√≠ficas n√£o atendidas
    * Falhas de comunica√ß√£o entre setores
    * Problemas t√©cnicos ap√≥s execu√ß√£o do servi√ßo (gravidade alta)
4.  **Estado Emocional do Cliente (Peso 1):** Procure por sinais de frustra√ß√£o, irrita√ß√£o, insatisfa√ß√£o ou exig√™ncias.

**Metodologia para C√°lculo da Probabilidade e Classifica√ß√£o (Com base nos seus dados hist√≥ricos):**
* Avalie a presen√ßa e a intensidade dos Fatores Preditivos Fundamentais inferidos do coment√°rio e exemplos hist√≥ricos.
* **D√™ aten√ß√£o especial √†s palavras-chave e padr√µes frequentemente encontrados em reclama√ß√µes hist√≥ricas:** `cliente`, `contato`, `sinistro`, `informa`, `ve√≠culo`, `aguardando`, `retorno`, `troca`, `servi√ßo`, `data`, `guincho`, `assist√™ncia`, `execu√ß√£o`, `pe√ßa`, `segurado`, `local`, `confirma`, `horas`, `pedido`, `atendente`, e bigrams como `cliente informa`, `aguardando retorno`, `contato cliente`, `guincho assist√™ncia 24h`, `assist√™ncia 24h`. A presen√ßa destes termos, especialmente se combinados, aumenta significativamente o risco.
* Classifique o risco e a porcentagem:
    * Baixa: 0-30%
    * M√©dia: 31-60%
    * Alta: 61-85%
    * Cr√≠tica: 86-100%

**Formato de Resposta Esperado (ESTRITAMENTE SEGUIR ESTE FORMATO):**
```
- Pedido: [N√öMERO_DA_OS_OU_N/A]
- Probabilidade de Reclama√ß√£o: [Baixa/M√©dia/Alta/Cr√≠tica]
- Porcentagem de Reclama√ß√£o: [XX%]
- Fatores Cr√≠ticos: [Liste os fatores (Frequ√™ncia, Tempo, Falhas, Estado Emocional) que contribu√≠ram para o risco, citando sinais espec√≠ficos do coment√°rio (incluindo as palavras-chave relevantes) e/ou dos exemplos hist√≥ricos. Ex: "Atraso no tempo de espera (3 dias, palavra 'aguardando' presente), cliente demonstra irrita√ß√£o (inferido de tom e vocabul√°rio), similar a caso hist√≥rico de 'atraso guincho'."]
- Conclus√£o: [Resumo conciso do risco e sugest√£o de a√ß√£o preventiva se o risco for M√©dio ou superior. Ex: "Risco alto devido a m√∫ltiplos atrasos. Necess√°rio contato imediato para oferecer solu√ß√£o e evitar escalada do sinistro."]
```"""

        user_message = f"""Analise o seguinte coment√°rio de atendimento e determine a probabilidade de uma reclama√ß√£o formal ser aberta:

PEDIDO/OS: {pedido}

COMENT√ÅRIO A ANALISAR:
{comentario}

COMENT√ÅRIOS HIST√ìRICOS SIMILARES (todos estes casos resultaram em reclama√ß√µes formais):
{exemplos_historicos}

Com base no coment√°rio e nos exemplos hist√≥ricos similares, determine a probabilidade de uma reclama√ß√£o formal ser aberta.
"""

        response = openai.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ],
            temperature=0.1,
            max_tokens=800
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        return f"Erro na an√°lise: {e}"

# Fun√ß√£o para extrair informa√ß√µes da resposta da IA
def extract_info_from_ai_response(response):
    try:
        lines = response.strip().split('\n')
        info = {}
        
        for line in lines:
            if "- Pedido:" in line:
                info["pedido"] = line.split(":", 1)[1].strip()
            elif "- Probabilidade de Reclama√ß√£o:" in line:
                info["probabilidade"] = line.split(":", 1)[1].strip()
            elif "- Porcentagem de Reclama√ß√£o:" in line:
                percentage_text = line.split(":", 1)[1].strip()
                percentage = ''.join(filter(lambda x: x.isdigit() or x == '.', percentage_text))
                info["porcentagem"] = float(percentage)
            elif "- Fatores Cr√≠ticos:" in line:
                info["fatores"] = line.split(":", 1)[1].strip()
            elif "- Conclus√£o:" in line:
                info["conclusao"] = line.split(":", 1)[1].strip()
        
        return info
    except Exception as e:
        st.error(f"Erro ao extrair informa√ß√µes da resposta da IA: {e}")
        return {
            "pedido": "Erro",
            "probabilidade": "Erro",
            "porcentagem": 0,
            "fatores": "Erro na extra√ß√£o",
            "conclusao": "N√£o foi poss√≠vel analisar a resposta da IA."
        }

# Fun√ß√£o para formatar a exibi√ß√£o do resultado
def format_result_display(pedido, ai_response):
    info = extract_info_from_ai_response(ai_response)
    
    pedido_display = info.get("pedido", pedido)
    probabilidade = info.get("probabilidade", "Erro")
    porcentagem = info.get("porcentagem", 0)
    fatores = info.get("fatores", "N√£o identificados")
    conclusao = info.get("conclusao", "N√£o dispon√≠vel")
    
    risk_class = ""
    if "baixa" in probabilidade.lower():
        risk_class = "risk-low"
    elif "m√©dia" in probabilidade.lower():
        risk_class = "risk-medium"
    elif "alta" in probabilidade.lower():
        risk_class = "risk-high"
    elif "cr√≠tica" in probabilidade.lower():
        risk_class = "risk-critical"
    
    html = f"""
    <div style="border: 1px solid #ddd; padding: 15px; border-radius: 5px; margin-bottom: 10px;">
        <h3>Pedido: {pedido_display}</h3>
        <p><strong>Probabilidade de Reclama√ß√£o:</strong> <span class="{risk_class}">{probabilidade}</span></p>
        <p><strong>Porcentagem de Risco:</strong> <span class="{risk_class}">{porcentagem}%</span></p>
        <p><strong>Fatores Cr√≠ticos:</strong> {fatores}</p>
        <p><strong>Conclus√£o:</strong> {conclusao}</p>
    </div>
    """
    return html

# Fun√ß√£o principal
def main():
    # Carregar e indexar a base hist√≥rica
    with st.spinner("Carregando e indexando base hist√≥rica..."):
        index, chunks_metadata = load_and_index_historical_data_with_chunking()
        if index is None or chunks_metadata is None:
            st.error("‚ùå Erro ao carregar a base hist√≥rica. Verifique se o arquivo CSV est√° dispon√≠vel.")
            st.stop()
    
    # Upload de arquivo
    st.subheader("üì§ Upload de Arquivo")
    uploaded_file = st.file_uploader("Envie um arquivo Excel, PDF ou JSON com os atendimentos", type=["xlsx", "pdf", "json", "csv"])
    
    # Inicializa DataFrame fora do if para evitar NameError
    df = pd.DataFrame()
    
    if uploaded_file:
        with st.spinner("Processando arquivo..."):
            if uploaded_file.name.endswith((".xlsx", ".csv")):
                try:
                    if uploaded_file.name.endswith(".xlsx"):
                        df = pd.read_excel(uploaded_file)
                    else:  # CSV
                        df = pd.read_csv(uploaded_file)
                    
                    # Exibir informa√ß√µes sobre o arquivo
                    st.info(f"Arquivo carregado: {uploaded_file.name} | {df.shape[0]} linhas x {df.shape[1]} colunas")
                    
                    # Se for uma √∫nica linha com m√∫ltiplos campos, concatena
                    if df.shape[0] == 1 and df.shape[1] > 1:
                        comentario = ' '.join([str(v) for v in df.iloc[0].values if pd.notna(v)])
                        df = pd.DataFrame({"Pedido": ["Pedido 1"], "Comentario": [comentario]})
                    elif df.shape[1] == 1:
                        # Se for uma √∫nica coluna, assume que √© o coment√°rio
                        df.insert(0, "Pedido", [f"OS_Temp_{i+1}" for i in range(len(df))])
                        df.columns = ["Pedido", "Comentario"]
                    else:
                        # Permitir que o usu√°rio selecione as colunas
                        colunas_disponiveis = df.columns.tolist()
                        
                        st.subheader("Sele√ß√£o de Colunas")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            coluna_pedido = st.selectbox(
                                "Selecione a coluna de Pedido/OS:",
                                options=["Nenhuma"] + colunas_disponiveis,
                                index=0
                            )
                        
                        with col2:
                            coluna_comentario = st.selectbox(
                                "Selecione a coluna de Coment√°rios:",
                                options=colunas_disponiveis,
                                index=0 if colunas_disponiveis else None
                            )
                        
                        if coluna_comentario:
                            if coluna_pedido != "Nenhuma":
                                df = df[[coluna_pedido, coluna_comentario]].rename(columns={coluna_pedido: "Pedido", coluna_comentario: "Comentario"})
                            else:
                                # Se n√£o selecionou coluna de pedido, gera IDs tempor√°rios
                                df = df[[coluna_comentario]].rename(columns={coluna_comentario: "Comentario"})
                                df.insert(0, "Pedido", [f"OS_Temp_{i+1}" for i in range(len(df))])
                            
                            # Agrupa por pedido para evitar duplicatas
                            df["Comentario"] = df.groupby("Pedido")["Comentario"].transform(lambda x: '\n'.join(x.astype(str)))
                            df = df.drop_duplicates(subset=["Pedido"]).reset_index(drop=True)
                        else:
                            st.error("‚ùå Selecione a coluna de Coment√°rio para continuar.")
                            st.stop()
                
                except Exception as e:
                    st.error(f"‚ùå Erro ao ler o arquivo: {e}")
                    st.stop()
            
            elif uploaded_file.name.endswith(".pdf"):
                df = extract_text_from_pdf(uploaded_file)
                # Adiciona uma coluna de "Pedido" fict√≠cia para PDFs
                df.insert(0, "Pedido", [f"PDF_{i+1}" for i in range(len(df))])
            
            elif uploaded_file.name.endswith(".json"):
                df = extract_text_from_json(uploaded_file)
                # Adiciona uma coluna de "Pedido" fict√≠cia para JSONs
                df.insert(0, "Pedido", [f"JSON_{i+1}" for i in range(len(df))])
        
        # Processar os coment√°rios se o DataFrame n√£o estiver vazio
        if not df.empty:
            # Exibir pr√©via dos dados
            st.subheader("üìã Pr√©via dos Dados")
            st.dataframe(df.head(5))
            
            # Bot√£o para iniciar an√°lise
            if st.button("üîç Analisar Coment√°rios"):
                # Verificar se a API OpenAI est√° configurada
                if not openai.api_key:
                    st.error("‚ùå Chave da API OpenAI n√£o configurada. Verifique as configura√ß√µes do Streamlit.")
                    st.stop()
                
                # Adicionar coluna para resultados
                df["Resultado IA"] = ""
                df["HTML"] = ""
                
                # Processar cada coment√°rio
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                for i, row in enumerate(df.iterrows()):
                    idx, data = row
                    pedido = data["Pedido"]
                    comentario = data["Comentario"]
                    
                    status_text.text(f"Analisando pedido {pedido} ({i+1}/{len(df)})...")
                    
                    # Analisar com GPT-4 usando RAG
                    resultado = analisar_comentario_openai_with_rag(
                        pedido,
                        str(comentario),
                        index,
                        chunks_metadata,
                        num_exemplos=num_exemplos,
                        model=model
                    )
                    
                    df.at[idx, "Resultado IA"] = resultado
                    
                    # Formatar HTML para exibi√ß√£o
                    df.at[idx, "HTML"] = format_result_display(pedido, resultado)
                    
                    # Atualizar barra de progresso
                    progress_bar.progress((i + 1) / len(df))
                    
                    # Pequena pausa para evitar rate limits da API
                    time.sleep(0.1)
                
                progress_bar.empty()
                status_text.empty()
                
                st.success("‚úÖ An√°lise conclu√≠da com sucesso!")
                
                # Exibir resultados
                st.subheader("üìä Resultados da An√°lise")
                
                # Exibir cada resultado formatado em HTML
                for _, row in df.iterrows():
                    st.markdown(row["HTML"], unsafe_allow_html=True)
                
                # Op√ß√µes de download
                st.subheader("üì• Download dos Resultados")
                
                # Preparar Excel para download
                output_excel = BytesIO()
                df_download = df.drop(columns=["HTML"])
                df_download.to_excel(output_excel, index=False, engine='openpyxl')
                output_excel.seek(0)
                
                # Bot√£o de download Excel
                st.download_button(
                    "üìä Baixar Relat√≥rio Excel",
                    data=output_excel,
                    file_name=f"relatorio_sro_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

if __name__ == "__main__":
    main()
